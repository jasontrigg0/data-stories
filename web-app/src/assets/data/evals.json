[
    {
        "eval": "MathArena Apex",
        "difficulty": 112.36731635031957
    },
    {
        "eval": "SWE Bench Pro (commercial) - Scale AI",
        "difficulty": 106.4709725254972
    },
    {
        "eval": "EnigmaEval",
        "difficulty": 99.5324691754748
    },
    {
        "eval": "ARC-AGI-2",
        "difficulty": 95.63655854273003
    },
    {
        "eval": "HLE",
        "difficulty": 89.96585819099653
    },
    {
        "eval": "FrontierMath 1-3 - Epoch AI",
        "difficulty": 87.25682992584171
    },
    {
        "eval": "Terminal-Bench (Terminus 1)",
        "difficulty": 81.28224384567177
    },
    {
        "eval": "SimpleQA",
        "difficulty": 79.13470024364403
    },
    {
        "eval": "Terminal-Bench 2 (terminus 2)",
        "difficulty": 78.91463985559885
    },
    {
        "eval": "WeirdML v2",
        "difficulty": 71.2262742605231
    },
    {
        "eval": "ARC-AGI-1",
        "difficulty": 70.47212145965956
    },
    {
        "eval": "Simplebench",
        "difficulty": 69.68537701103132
    },
    {
        "eval": "Multichallenge",
        "difficulty": 67.18626734566048
    },
    {
        "eval": "HMMT Feb 2025",
        "difficulty": 65.71272254766126
    },
    {
        "eval": "SWE Verified",
        "difficulty": 59.53154845616027
    },
    {
        "eval": "WeirdML",
        "difficulty": 58.932962314995194
    },
    {
        "eval": "Tau Bench Telecom",
        "difficulty": 58.68672850063006
    },
    {
        "eval": "MMMU Pro",
        "difficulty": 58.074797732658745
    },
    {
        "eval": "aider polyglot",
        "difficulty": 58.0728072261937
    },
    {
        "eval": "livecodebench 010125-050125",
        "difficulty": 57.73794267411699
    },
    {
        "eval": "fiction livebench 120k",
        "difficulty": 56.82392138476699
    },
    {
        "eval": "AIME 2024",
        "difficulty": 54.903987171060926
    },
    {
        "eval": "AIME 2025 (matharena)",
        "difficulty": 54.78802875741326
    },
    {
        "eval": "livebench 0530",
        "difficulty": 49.631746819695564
    },
    {
        "eval": "Tau Bench Retail",
        "difficulty": 47.83128395593449
    },
    {
        "eval": "GPQA diamond",
        "difficulty": 39.47421953085538
    },
    {
        "eval": "MATH",
        "difficulty": 21.996185609132688
    },
    {
        "eval": "MMMU",
        "difficulty": 14.332236711759943
    },
    {
        "eval": "MMLU-Pro",
        "difficulty": 13.294143059080318
    },
    {
        "eval": "Truthful QA (MC1, 0-shot)",
        "difficulty": 8.114603212840903
    },
    {
        "eval": "HumanEval",
        "difficulty": 0.09925400978028573
    },
    {
        "eval": "MMMLU",
        "difficulty": -13.584583946002864
    },
    {
        "eval": "ARC challenge (25-shot) AI2",
        "difficulty": -29.121917271521745
    },
    {
        "eval": "MMLU (5 shot)",
        "difficulty": -33.509649373112914
    },
    {
        "eval": "MGSM",
        "difficulty": -34.05276011448765
    },
    {
        "eval": "TriviaQA (few shot)",
        "difficulty": -34.64770296048383
    },
    {
        "eval": "DROP (f1 3-shot)",
        "difficulty": -45.32529170542714
    },
    {
        "eval": "Hellaswag (10-shot)",
        "difficulty": -74.26554596743561
    },
    {
        "eval": "METR 50% (ln)",
        "difficulty": "N/A"
    },
    {
        "eval": "webdev arena-new",
        "difficulty": "N/A"
    },
    {
        "eval": "webdev arena-old",
        "difficulty": "N/A"
    },
    {
        "eval": "lmarena-new",
        "difficulty": "N/A"
    },
    {
        "eval": "lmarena-old",
        "difficulty": "N/A"
    },
    {
        "eval": "FACTS",
        "difficulty": "N/A"
    },
    {
        "eval": "Lambada",
        "difficulty": "N/A"
    },
    {
        "eval": "WinoGrande (5-shot)",
        "difficulty": "N/A"
    },
    {
        "eval": "Codeforces",
        "difficulty": "N/A"
    },
    {
        "eval": "Winograd Schema Challenge",
        "difficulty": "N/A"
    }
]