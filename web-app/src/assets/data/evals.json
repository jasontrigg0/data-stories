[
    {
        "eval": "EnigmaEval",
        "difficulty": 98.84584814410039
    },
    {
        "eval": "FrontierMath (private)",
        "difficulty": 93.4766177404992
    },
    {
        "eval": "HLE",
        "difficulty": 92.8430848513224
    },
    {
        "eval": "SimpleQA",
        "difficulty": 77.09849488902695
    },
    {
        "eval": "ARC-AGI-1",
        "difficulty": 70.4620963009525
    },
    {
        "eval": "Simplebench",
        "difficulty": 69.77895960024266
    },
    {
        "eval": "Multichallenge",
        "difficulty": 67.0343592270252
    },
    {
        "eval": "SWE Verified",
        "difficulty": 60.16315357905118
    },
    {
        "eval": "WeirdML",
        "difficulty": 58.67995614489168
    },
    {
        "eval": "livecodebench 010125-050125",
        "difficulty": 58.273065462552836
    },
    {
        "eval": "aider polyglot",
        "difficulty": 57.27509115100914
    },
    {
        "eval": "AIME 2024",
        "difficulty": 55.12407153846683
    },
    {
        "eval": "fiction livebench 120k",
        "difficulty": 55.061036128702966
    },
    {
        "eval": "AIME 2025 (matharena)",
        "difficulty": 54.23955846149229
    },
    {
        "eval": "MMLU-Pro",
        "difficulty": 48.98007258046999
    },
    {
        "eval": "livebench 0530",
        "difficulty": 48.40460121722678
    },
    {
        "eval": "GPQA diamond",
        "difficulty": 38.68314828414542
    },
    {
        "eval": "MATH",
        "difficulty": 20.67697889747086
    },
    {
        "eval": "MMMU",
        "difficulty": 11.843270289708382
    },
    {
        "eval": "Truthful QA (MC1, 0-shot)",
        "difficulty": 8.694271515333229
    },
    {
        "eval": "HumanEval",
        "difficulty": -1.245877833217401
    },
    {
        "eval": "ARC challenge (25-shot) AI2",
        "difficulty": -32.35341218619075
    },
    {
        "eval": "MMLU (5 shot)",
        "difficulty": -34.298242366191396
    },
    {
        "eval": "TriviaQA (few shot)",
        "difficulty": -34.9725228647861
    },
    {
        "eval": "MGSM",
        "difficulty": -35.227399165576436
    },
    {
        "eval": "DROP (f1 3-shot)",
        "difficulty": -47.76951695351066
    },
    {
        "eval": "Hellaswag (10-shot)",
        "difficulty": -68.89675484730097
    },
    {
        "eval": "webdev arena",
        "difficulty": "N/A"
    },
    {
        "eval": "lmarena",
        "difficulty": "N/A"
    },
    {
        "eval": "FACTS",
        "difficulty": "N/A"
    },
    {
        "eval": "Lambada",
        "difficulty": "N/A"
    },
    {
        "eval": "WinoGrande (5-shot)",
        "difficulty": "N/A"
    },
    {
        "eval": "Codeforces",
        "difficulty": "N/A"
    },
    {
        "eval": "Winograd Schema Challenge",
        "difficulty": "N/A"
    }
]